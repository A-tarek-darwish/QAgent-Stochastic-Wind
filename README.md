This file contains a Python code for a SARSA Agent that navigates a maze that contains immobile obstacles and stochastic wind. It is initially set to run for a maximum of 500 episodes. It also contains a GUI to show the optimal policy developed by the agent and a graph showing the training performance across episodes. 


Grid and Reward Information:

â€¢ The grid world size is 6x6.
â€¢ The environment is undiscounted (i.e. ğ›¾ = 1).
â€¢ The goal should be at the bottom right corner.
â€¢ There are obstacles in the environment as shown in the above figure at the following positions (1, 2), (1, 3), (1, 4), (4, 2), (4, 3) and (4, 4).
â€¢ The allowable actions are â€œUPâ€, â€œDOWNâ€, â€œLEFTâ€ and â€œRIGHTâ€.
â€¢ The wind acts upwards in the 2 middle columns of the environment; such that there is a 70% probability of the agent being pushed upwards regardless of the action taken.
â€¢ The rewards are described as follows. Reaching the goal position is rewarded by 20 units. Taking an action against the wind direction is penalized by 5 units as it consumes the agentâ€™s energy. Also, colliding with an obstacle results in a penalty of 5 units. The agent should be motivated to reach the goal as soon as possible; so, each time step is otherwise penalized by 1 unit.
